{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from keras import layers, Input\n",
    "from keras.models import Model\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_final_2 = pd.read_csv('./total_data_final_2.csv')\n",
    "total_data_final_2.columns\n",
    "df = total_data_final_2[['folder_name','image_num','category_label','category_name',\n",
    "                         'category_type','texture','shape','style']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198558, 8)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# category_type = 3 삭제\n",
    "df = df[df.category_type != 3]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder_name</th>\n",
       "      <th>image_num</th>\n",
       "      <th>category_label</th>\n",
       "      <th>category_name</th>\n",
       "      <th>category_type</th>\n",
       "      <th>texture</th>\n",
       "      <th>shape</th>\n",
       "      <th>style</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sheer_Pleated-Front_Blouse</td>\n",
       "      <td>img_00000001.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>shift</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sheer_Pleated-Front_Blouse</td>\n",
       "      <td>img_00000002.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>shift</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheer_Pleated-Front_Blouse</td>\n",
       "      <td>img_00000003.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>slip</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sheer_Pleated-Front_Blouse</td>\n",
       "      <td>img_00000004.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sheer_Pleated-Front_Blouse</td>\n",
       "      <td>img_00000005.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>shark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198553</th>\n",
       "      <td>Destroyed_Denim_Cutoffs</td>\n",
       "      <td>img_00000015.jpg</td>\n",
       "      <td>24</td>\n",
       "      <td>Cutoffs</td>\n",
       "      <td>2</td>\n",
       "      <td>diamond</td>\n",
       "      <td>distressed skinny</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198554</th>\n",
       "      <td>Destroyed_Denim_Cutoffs</td>\n",
       "      <td>img_00000016.jpg</td>\n",
       "      <td>24</td>\n",
       "      <td>Cutoffs</td>\n",
       "      <td>2</td>\n",
       "      <td>diamond print</td>\n",
       "      <td>denim pencil</td>\n",
       "      <td>elegant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198555</th>\n",
       "      <td>Destroyed_Denim_Cutoffs</td>\n",
       "      <td>img_00000017.jpg</td>\n",
       "      <td>24</td>\n",
       "      <td>Cutoffs</td>\n",
       "      <td>2</td>\n",
       "      <td>diamond print</td>\n",
       "      <td>denim pencil</td>\n",
       "      <td>rolling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198556</th>\n",
       "      <td>Destroyed_Denim_Cutoffs</td>\n",
       "      <td>img_00000018.jpg</td>\n",
       "      <td>24</td>\n",
       "      <td>Cutoffs</td>\n",
       "      <td>2</td>\n",
       "      <td>paint</td>\n",
       "      <td>distressed low-rise</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198557</th>\n",
       "      <td>Destroyed_Denim_Cutoffs</td>\n",
       "      <td>img_00000019.jpg</td>\n",
       "      <td>24</td>\n",
       "      <td>Cutoffs</td>\n",
       "      <td>2</td>\n",
       "      <td>linen-blend</td>\n",
       "      <td>skinny stretch</td>\n",
       "      <td>roman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198558 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       folder_name         image_num  category_label  \\\n",
       "0       Sheer_Pleated-Front_Blouse  img_00000001.jpg               3   \n",
       "1       Sheer_Pleated-Front_Blouse  img_00000002.jpg               3   \n",
       "2       Sheer_Pleated-Front_Blouse  img_00000003.jpg               3   \n",
       "3       Sheer_Pleated-Front_Blouse  img_00000004.jpg               3   \n",
       "4       Sheer_Pleated-Front_Blouse  img_00000005.jpg               3   \n",
       "...                            ...               ...             ...   \n",
       "198553     Destroyed_Denim_Cutoffs  img_00000015.jpg              24   \n",
       "198554     Destroyed_Denim_Cutoffs  img_00000016.jpg              24   \n",
       "198555     Destroyed_Denim_Cutoffs  img_00000017.jpg              24   \n",
       "198556     Destroyed_Denim_Cutoffs  img_00000018.jpg              24   \n",
       "198557     Destroyed_Denim_Cutoffs  img_00000019.jpg              24   \n",
       "\n",
       "       category_name  category_type        texture                shape  \\\n",
       "0             Blouse              1            NaN                shift   \n",
       "1             Blouse              1            NaN                shift   \n",
       "2             Blouse              1            NaN                 slip   \n",
       "3             Blouse              1            NaN                  NaN   \n",
       "4             Blouse              1            NaN                  NaN   \n",
       "...              ...            ...            ...                  ...   \n",
       "198553       Cutoffs              2        diamond    distressed skinny   \n",
       "198554       Cutoffs              2  diamond print         denim pencil   \n",
       "198555       Cutoffs              2  diamond print         denim pencil   \n",
       "198556       Cutoffs              2          paint  distressed low-rise   \n",
       "198557       Cutoffs              2    linen-blend       skinny stretch   \n",
       "\n",
       "          style  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4         shark  \n",
       "...         ...  \n",
       "198553      NaN  \n",
       "198554  elegant  \n",
       "198555  rolling  \n",
       "198556      NaN  \n",
       "198557    roman  \n",
       "\n",
       "[198558 rows x 8 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폴더 생성 함수\n",
    "\n",
    "def createfolder(foler_dir):\n",
    "    try:\n",
    "        if not os.path.exists(folder_dir):\n",
    "            os.makedirs(folder_dir)\n",
    "    except OSError:\n",
    "        print('Error Creating directory'+folder_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category_name 폴더 만들기\n",
    "\n",
    "category_list = list(df['category_name'].unique())\n",
    "\n",
    "for folder_name in category_list:\n",
    "    a = 'C:/Users/student/Desktop/category/'\n",
    "    folder_dir = a + folder_name\n",
    "    createfolder(folder_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "65000\n",
      "70000\n",
      "75000\n",
      "80000\n",
      "85000\n",
      "90000\n",
      "95000\n",
      "100000\n",
      "105000\n",
      "110000\n",
      "115000\n",
      "120000\n",
      "125000\n",
      "130000\n",
      "135000\n",
      "140000\n",
      "145000\n",
      "150000\n",
      "155000\n",
      "160000\n",
      "165000\n",
      "170000\n",
      "175000\n",
      "180000\n",
      "185000\n",
      "190000\n",
      "195000\n"
     ]
    }
   ],
   "source": [
    "# category_name에 맞춰서 사진 다시 저장\n",
    "\n",
    "for _ in range(df.shape[0]):\n",
    "    num = str(_)\n",
    "    category_name = df['category_name'][_]\n",
    "    img_folder = df['folder_name'][_] \n",
    "    img_name = df['image_num'][_] \n",
    "    full_dir = str('D:/Project/img/' + img_folder + '/' + img_name) \n",
    "    \n",
    "    img = cv2.imread(full_dir)\n",
    "    img = cv2.resize(img, (150,150))\n",
    "    \n",
    "    new_dir = str('C:/Users/student/Desktop/category/'+ category_name)\n",
    "    new_name = new_dir + '/' + category_name + '_' + num + '.jpg'\n",
    "    cv2.imwrite(new_name, img) \n",
    "    \n",
    "    if _ % 5000 == 0:\n",
    "        print(_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## category_name으로 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range = 20,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    rescale = 1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 150, 150, 16)      432       \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 150, 150, 16)      48        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 150, 150, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 38, 38, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 38, 38, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 38, 38, 32)        4608      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 38, 38, 32)        96        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 38, 38, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 10, 10, 64)        18432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 10, 10, 64)        192       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 3, 3, 128)         73728     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 3, 3, 128)         384       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               590336    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 36)                18468     \n",
      "=================================================================\n",
      "Total params: 706,724\n",
      "Trainable params: 706,244\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3, 3), padding='same', use_bias=False, input_shape=(150,150, 3)))\n",
    "model.add(BatchNormalization(axis=3, scale=False))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    " \n",
    "model.add(Conv2D(32, (3, 3), padding='same', use_bias=False))\n",
    "model.add(BatchNormalization(axis=3, scale=False))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    " \n",
    "model.add(Conv2D(64, (3, 3), padding='same', use_bias=False))\n",
    "model.add(BatchNormalization(axis=3, scale=False))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    " \n",
    "model.add(Conv2D(128, (3, 3), padding='same', use_bias=False))\n",
    "model.add(BatchNormalization(axis=3, scale=False))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    " \n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(36, activation='softmax'))\n",
    "model.summary()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 158860 images belonging to 36 classes.\n",
      "Found 39698 images belonging to 36 classes.\n"
     ]
    }
   ],
   "source": [
    "# Compiling the CNN\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "# 데이터 셋\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "#                                   rotation_range=10,\n",
    "#                                   width_shift_range=0.2,\n",
    "#                                   height_shift_range=0.2,\n",
    "#                                   shear_range=0.7,\n",
    "#                                   zoom_range=[0.9, 2.2],\n",
    "#                                   horizontal_flip=True,\n",
    "#                                   vertical_flip=True,\n",
    "#                                   fill_mode='nearest',\n",
    "                                   validation_split=0.20)\n",
    " \n",
    "training_set = train_datagen.flow_from_directory('C:/Users/student/Desktop/category',\n",
    "                                                 target_size = (150,150),\n",
    "                                                 batch_size = 15,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 subset=\"training\"\n",
    "                                                )\n",
    "validation_set = train_datagen.flow_from_directory('C:/Users/student/Desktop/category',\n",
    "                                                 target_size = (150,150),\n",
    "                                                 batch_size = 10,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 subset=\"validation\"\n",
    "                                                  )\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15000\n",
      "20/20 [==============================] - 15s 729ms/step - loss: 1.9796 - acc: 0.3700 - val_loss: 2.0967 - val_acc: 0.2900\n",
      "Epoch 2/15000\n",
      "13/20 [==================>...........] - ETA: 4s - loss: 1.8935 - acc: 0.4000"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import CSVLogger\n",
    " \n",
    "csv_logger = CSVLogger('./log.csv', append=True, separator=';')\n",
    " \n",
    " \n",
    "hist = model.fit_generator(training_set,\n",
    "                         steps_per_epoch = 20, #20\n",
    "                         epochs = 15000,  #1000\n",
    "                         validation_data = validation_set,\n",
    "                         validation_steps = 10,#10\n",
    "                         callbacks=[csv_logger])\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    " \n",
    "model.save('cnn_attraction_keras_model.h5')\n",
    " \n",
    "# output = classifier.predict_generator(test_set, steps=5)\n",
    "# print(test_set.class_indices)\n",
    "# print(output)\n",
    " \n",
    "# 모델 평가하기\n",
    "print(\"-- Evaluate --\")\n",
    " \n",
    "scores = model.evaluate_generator(\n",
    "            validation_set,\n",
    "            steps = 10)\n",
    " \n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
    " \n",
    "# 모델 예측하기\n",
    "print(\"-- Predict --\")\n",
    " \n",
    "output = model.predict_generator(\n",
    "            validation_set,\n",
    "            steps = 100)\n",
    "print(validation_set.class_indices)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    " \n",
    "fig, loss_ax = plt.subplots()\n",
    " \n",
    "acc_ax = loss_ax.twinx()\n",
    " \n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "#loss_ax.set_ylim([0.0, 0.5])\n",
    " \n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "#acc_ax.set_ylim([0.8, 1.0])\n",
    " \n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    " \n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cpu_env] *",
   "language": "python",
   "name": "conda-env-cpu_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
