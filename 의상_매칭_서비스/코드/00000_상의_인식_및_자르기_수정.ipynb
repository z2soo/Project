{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import argparse\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from io import BytesIO\n",
    "import json\n",
    "import pprint\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from keras import layers, Input, models, optimizers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import MaxPooling2D, Conv2D,Activation, Dropout, Flatten, Dense\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 분리 및 예측 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperate_n_predict(img_dir, \n",
    "                       model_dir_1,\n",
    "                       model_dir_2,\n",
    "                       model_dir_3,\n",
    "                       model_dir_4, var):\n",
    "    \n",
    "    conv_base = VGG16(weights = 'imagenet',include_top=False,input_shape=(150,150,3))\n",
    "    \n",
    "    model_2 = load_model(model_dir_2)\n",
    "    model_3 = load_model(model_dir_3)\n",
    "    model_4 = load_model(model_dir_4)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 사용할 model 설정\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(256, activation='relu', input_dim = 4 * 4 * 512))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(7, activation='softmax'))\n",
    "    model.compile(optimizer = optimizers.RMSprop(lr=2e-5),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "    model.load_weights(model_dir)    \n",
    "    \n",
    "    \n",
    "    # 카카오 API 설정\n",
    "    API_URL = 'https://kapi.kakao.com/v1/vision/product/detect'\n",
    "    MYAPP_KEY = '7af88d85dc96c6e9ec2ebadca618519a'\n",
    "    url = \"https://kapi.kakao.com/v1/vision/product/detect\"       \n",
    "    headers = {'Authorization': 'KakaoAK {}'.format(MYAPP_KEY)}\n",
    "    files = { 'file' : open(img_dir, 'rb')}\n",
    "    response = requests.post(url, headers=headers, files=files)\n",
    "    \n",
    "    \n",
    "    # 카카오 API 저장 및 예외 상황 설정\n",
    "    info = []\n",
    "    result = response.json()\n",
    "\n",
    "    if 'result' in result:                                                    \n",
    "        fig_w, fig_h = result['result']['width'], result['result']['height']\n",
    "    else:\n",
    "        return ['NA','NA','NA','NA','NA','NA','NA']\n",
    "\n",
    "    if 'objects' in result['result']:\n",
    "        mylist = result['result']['objects']\n",
    "        cnt = 0\n",
    "        for objects in mylist:\n",
    "            if objects['class'] in ['shirts','blouse','t-shirts','pants','outer','skirt','one-piece']:\n",
    "                cnt = cnt+1\n",
    "        if cnt > 4:\n",
    "            return ['NA','NA','NA','NA','NA','NA','NA']\n",
    "    else:\n",
    "        return ['NA','NA','NA','NA','NA','NA','NA']\n",
    "        \n",
    "        \n",
    "    for each in result['result']['objects']:                        \n",
    "            each = list(each.values())                                            \n",
    "            info.append(each)\n",
    "            \n",
    "    \n",
    "    \n",
    "    upper = list()\n",
    "    lower = list()\n",
    "    for _ in result['result']['objects']:\n",
    "        if _['class'] in ('t-shirts', 'shirts'):\n",
    "            upper = _\n",
    "        elif _['class'] in ('skirt', 'pants'):\n",
    "            lower = _\n",
    "            \n",
    "    x1 = lower['x1']*fig_w -5\n",
    "    y1 = lower['y1']*fig_h -5\n",
    "    w1 = lower['x2']*fig_w +5\n",
    "    h1 = lower['y2']*fig_h +5\n",
    "\n",
    "    x2 = upper['x1']*fig_w -5\n",
    "    y2 = upper['y1']*fig_h -5\n",
    "    w2 = upper['x2']*fig_w +5\n",
    "    h2 = y1\n",
    "        \n",
    "    \n",
    "    top_1 = []    \n",
    "    bottom_1 = []\n",
    "    top_2 = []    \n",
    "    bottom_2 = []    \n",
    "    top_3 = []    \n",
    "    bottom_3 = []    \n",
    "    top_4 = []    \n",
    "    bottom_4 = []    \n",
    "    \n",
    "    \n",
    "    for _ in range(len(info)):\n",
    "        img = Image.open(img_dir)\n",
    "        category = info[_][4]\n",
    "        \n",
    "        if category in ('shirts','t-shirts'):\n",
    "\n",
    "            img = img.crop((x2,y2,w2,h2))                               \n",
    "            img.show() \n",
    "      \n",
    "            # 4) 자른 사진 model 예측 \n",
    "            img = img.resize((150,150))\n",
    "            data = np.array(img)\n",
    "            data = data.astype('float')\n",
    "            data = data/255\n",
    "            data = data.reshape((1,150,150,3))\n",
    "            \n",
    "            p = conv_base.predict(data)\n",
    "            p = p.reshape((-1,8192))\n",
    "            p = model.predict_classes(p)[0]\n",
    "            p = var[p]\n",
    "            top_1.append(p)\n",
    "        \n",
    "            result_2 = var[model_2.predict_classes(data)[0]]\n",
    "            top_2.append(result_2)\n",
    "            \n",
    "            result_3 = var[model_3.predict_classes(data)[0]]\n",
    "            top_3.append(result_3)\n",
    "        \n",
    "            result_4 = var[model_4.predict_classes(data)[0]]\n",
    "            top_4.append(result_4)        \n",
    "        \n",
    "        elif category in ('pants','skirt'): \n",
    "            img = img.crop((x1,y1,w1,h1))                               \n",
    "            img.show() \n",
    "            \n",
    "            # 4) 자른 사진 model 예측 \n",
    "            img = img.resize((150,150))\n",
    "            data = np.array(img)\n",
    "            data = data.astype('float')\n",
    "            data = data/255\n",
    "            data = data.reshape((1,150,150,3))\n",
    "\n",
    "            p = conv_base.predict(data)\n",
    "            p = p.reshape((-1,8192))\n",
    "            p = model.predict_classes(p)[0]\n",
    "            p = var[p]\n",
    "            bottom_1.append(p)\n",
    "            \n",
    "            result_2 = var[model_2.predict_classes(data)[0]]\n",
    "            bottom_2.append(result_2)\n",
    "            \n",
    "            result_3 = var[model_3.predict_classes(data)[0]]\n",
    "            bottom_3.append(result_3)\n",
    "        \n",
    "            result_4 = var[model_4.predict_classes(data)[0]]\n",
    "            bottom_4.append(result_4)        \n",
    "        \n",
    "            \n",
    "    return (f'model_1 :{top_1, bottom_1} \\n model_2 :{top_2, bottom_2} \\n model_3 :{top_3, bottom_3}\\n model_4 :{top_4, bottom_4}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 여러 이미지 상하의 pattern 예측 및 값 저장 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하나의 폴더에 있는 여러 이미지를 불러와서 상하의 crop 하고 pattern 예측한 값을\n",
    "# 돌려받아 이를 dataframe 으로 append 및 하나의 파일로 저장하는 함수 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_multi(folder_dir, model_dir, var):\n",
    "    \n",
    "    file_list = os.listdir(folder_dir)\n",
    "    \n",
    "    for _ in range(len(file_list)):\n",
    "        img_dir = folder_dir + '/' + file_list[_]\n",
    "        Image.open(img_dir)\n",
    "        k = seperate_n_predict(img_dir, \n",
    "                               model_dir_1,\n",
    "                               model_dir_2,\n",
    "                               model_dir_3,\n",
    "                               model_dir_4,\n",
    "                               var)\n",
    "        print(f'========{file_list[_]}==========')\n",
    "        print(k)\n",
    "   \n",
    "\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = ['check', 'dot', 'floral', 'graphic', 'leopard', 'none', 'stripe']\n",
    "folder_dir = './img/test'    \n",
    "model_dir_1 = './model/pattern_9985.h5'   \n",
    "model_dir_2 = './model/pattern_7class_정확도77.h5'\n",
    "model_dir_3 = './model/pattern_new7class_6578.h5'\n",
    "model_dir_4 = './model/pattern_no_camo_정확도76.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========Aa (10).jpg==========\n",
      "model_1 :(['graphic'], ['check']) \n",
      " model_2 :(['graphic'], ['none']) \n",
      " model_3 :(['graphic'], ['floral'])\n",
      " model_4 :(['graphic'], ['none'])\n",
      "========Aa (14).jpg==========\n",
      "model_1 :(['none'], ['check']) \n",
      " model_2 :(['none'], ['check']) \n",
      " model_3 :(['none'], ['check'])\n",
      " model_4 :(['none'], ['check'])\n",
      "========Aa (15).jpg==========\n",
      "model_1 :(['none'], ['check']) \n",
      " model_2 :(['none'], ['check']) \n",
      " model_3 :(['none'], ['floral'])\n",
      " model_4 :(['none'], ['none'])\n",
      "========Aa (16).jpg==========\n",
      "model_1 :(['graphic'], ['check']) \n",
      " model_2 :(['none'], ['check']) \n",
      " model_3 :(['graphic'], ['check'])\n",
      " model_4 :(['graphic'], ['check'])\n",
      "========Aa (17).jpg==========\n",
      "model_1 :(['none'], ['check']) \n",
      " model_2 :(['none'], ['check']) \n",
      " model_3 :(['none'], ['floral'])\n",
      " model_4 :(['none'], ['none'])\n"
     ]
    }
   ],
   "source": [
    "predict_multi(folder_dir, model_dir, var)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cpu_env] *",
   "language": "python",
   "name": "conda-env-cpu_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
