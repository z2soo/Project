{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import layers, Input, models, optimizers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import MaxPooling2D, Conv2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras_preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "original_dataset_dir = './data/clothes_category/'\n",
    "\n",
    "base_dir = './data/clothes_category_small'\n",
    "# os.mkdir(base_dir)\n",
    "\n",
    "train_dir = os.path.join(base_dir,'train')\n",
    "os.mkdir(train_dir)\n",
    "validation_dir = os.path.join(base_dir,'validation')\n",
    "os.mkdir(validation_dir)\n",
    "test_dir = os.path.join(base_dir,'test')\n",
    "os.mkdir(test_dir)\n",
    "\n",
    "train_Blouse_dir = os.path.join(train_dir, 'Blouse')\n",
    "os.mkdir(train_Blouse_dir)\n",
    "\n",
    "train_Chiffon_skirt_dir = os.path.join(train_dir, 'Chiffon_skirt')\n",
    "os.mkdir(train_Chiffon_skirt_dir)\n",
    "\n",
    "train_Coat_dir = os.path.join(train_dir, 'Coat')\n",
    "os.mkdir(train_Coat_dir)\n",
    "\n",
    "train_Cotten_long_pants_dir = os.path.join(train_dir, 'Cotten_long_pants')\n",
    "os.mkdir(train_Cotten_long_pants_dir)\n",
    "\n",
    "train_Cutoffs_dir = os.path.join(train_dir, 'Cutoffs')\n",
    "os.mkdir(train_Cutoffs_dir)\n",
    "\n",
    "train_H_line_skirt_dir = os.path.join(train_dir, 'H_line_skirt')\n",
    "os.mkdir(train_H_line_skirt_dir)\n",
    "\n",
    "train_Hoodie_dir = os.path.join(train_dir, 'Hoodie')\n",
    "os.mkdir(train_Hoodie_dir)\n",
    "\n",
    "train_Jacket_dir = os.path.join(train_dir, 'Jacket')\n",
    "os.mkdir(train_Jacket_dir)\n",
    "\n",
    "train_Jeans_dir = os.path.join(train_dir, 'Jeans')\n",
    "os.mkdir(train_Jeans_dir)\n",
    "\n",
    "train_Long_sleeve_tee_dir = os.path.join(train_dir, 'Long_sleeve_tee')\n",
    "os.mkdir(train_Long_sleeve_tee_dir)\n",
    "\n",
    "train_Shirts_dir = os.path.join(train_dir, 'Shirts')\n",
    "os.mkdir(train_Shirts_dir)\n",
    "\n",
    "train_Short_sleeve_tee_dir = os.path.join(train_dir, 'Short_sleeve_tee')\n",
    "os.mkdir(train_Short_sleeve_tee_dir)\n",
    "\n",
    "train_Sweater_dir = os.path.join(train_dir, 'Sweater')\n",
    "os.mkdir(train_Sweater_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_Blouse_dir = os.path.join(validation_dir, 'Blouse')\n",
    "os.mkdir(validation_Blouse_dir)\n",
    "\n",
    "validation_Chiffon_skirt_dir = os.path.join(validation_dir, 'Chiffon_skirt')\n",
    "os.mkdir(validation_Chiffon_skirt_dir)\n",
    "\n",
    "validation_Coat_dir = os.path.join(validation_dir, 'Coat')\n",
    "os.mkdir(validation_Coat_dir)\n",
    "\n",
    "validation_Cotten_long_pants_dir = os.path.join(validation_dir, 'Cotten_long_pants')\n",
    "os.mkdir(validation_Cotten_long_pants_dir)\n",
    "\n",
    "validation_Cutoffs_dir = os.path.join(validation_dir, 'Cutoffs')\n",
    "os.mkdir(validation_Cutoffs_dir)\n",
    "\n",
    "validation_H_line_skirt_dir = os.path.join(validation_dir, 'H_line_skirt')\n",
    "os.mkdir(validation_H_line_skirt_dir)\n",
    "\n",
    "validation_Hoodie_dir = os.path.join(validation_dir, 'Hoodie')\n",
    "os.mkdir(validation_Hoodie_dir)\n",
    "\n",
    "validation_Jacket_dir = os.path.join(validation_dir, 'Jacket')\n",
    "os.mkdir(validation_Jacket_dir)\n",
    "\n",
    "validation_Jeans_dir = os.path.join(validation_dir, 'Jeans')\n",
    "os.mkdir(validation_Jeans_dir)\n",
    "\n",
    "validation_Long_sleeve_tee_dir = os.path.join(validation_dir, 'Long_sleeve_tee')\n",
    "os.mkdir(validation_Long_sleeve_tee_dir)\n",
    "\n",
    "validation_Shirts_dir = os.path.join(validation_dir, 'Shirts')\n",
    "os.mkdir(validation_Shirts_dir)\n",
    "\n",
    "validation_Short_sleeve_tee_dir = os.path.join(validation_dir, 'Short_sleeve_tee')\n",
    "os.mkdir(validation_Short_sleeve_tee_dir)\n",
    "\n",
    "validation_Sweater_dir = os.path.join(validation_dir, 'Sweater')\n",
    "os.mkdir(validation_Sweater_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Blouse_dir = os.path.join(test_dir, 'Blouse')\n",
    "os.mkdir(test_Blouse_dir)\n",
    "\n",
    "test_Chiffon_skirt_dir = os.path.join(test_dir, 'Chiffon_skirt')\n",
    "os.mkdir(test_Chiffon_skirt_dir)\n",
    "\n",
    "test_Coat_dir = os.path.join(test_dir, 'Coat')\n",
    "os.mkdir(test_Coat_dir)\n",
    "\n",
    "test_Cotten_long_pants_dir = os.path.join(test_dir, 'Cotten_long_pants')\n",
    "os.mkdir(test_Cotten_long_pants_dir)\n",
    "\n",
    "test_Cutoffs_dir = os.path.join(test_dir, 'Cutoffs')\n",
    "os.mkdir(test_Cutoffs_dir)\n",
    "\n",
    "test_H_line_skirt_dir = os.path.join(test_dir, 'H_line_skirt')\n",
    "os.mkdir(test_H_line_skirt_dir)\n",
    "\n",
    "test_Hoodie_dir = os.path.join(test_dir, 'Hoodie')\n",
    "os.mkdir(test_Hoodie_dir)\n",
    "\n",
    "test_Jacket_dir = os.path.join(test_dir, 'Jacket')\n",
    "os.mkdir(test_Jacket_dir)\n",
    "\n",
    "test_Jeans_dir = os.path.join(test_dir, 'Jeans')\n",
    "os.mkdir(test_Jeans_dir)\n",
    "\n",
    "test_Long_sleeve_tee_dir = os.path.join(test_dir, 'Long_sleeve_tee')\n",
    "os.mkdir(test_Long_sleeve_tee_dir)\n",
    "\n",
    "test_Shirts_dir = os.path.join(test_dir, 'Shirts')\n",
    "os.mkdir(test_Shirts_dir)\n",
    "\n",
    "test_Short_sleeve_tee_dir = os.path.join(test_dir, 'Short_sleeve_tee')\n",
    "os.mkdir(test_Short_sleeve_tee_dir)\n",
    "\n",
    "test_Sweater_dir = os.path.join(test_dir, 'Sweater')\n",
    "os.mkdir(test_Sweater_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['Blouse{}.jpg'.format(i) for i in range(211)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_Blouse_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "\n",
    "fnames = ['Blouse{}.jpg'.format(i) for i in range(211,316)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_Blouse_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "    \n",
    "fnames = ['Blouse{}.jpg'.format(i) for i in range(316,421)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_Blouse_dir, fname)\n",
    "    shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['Chiffon_skirt{}.jpg'.format(i) for i in range(276)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_Chiffon_skirt_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "\n",
    "fnames = ['Chiffon_skirt{}.jpg'.format(i) for i in range(276,414)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_Chiffon_skirt_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "    \n",
    "fnames = ['Chiffon_skirt{}.jpg'.format(i) for i in range(414,552)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_Chiffon_skirt_dir, fname)\n",
    "    shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['Coat{}.jpg'.format(i) for i in range(299)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_Coat_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "\n",
    "fnames = ['Coat{}.jpg'.format(i) for i in range(299,449)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_Coat_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "    \n",
    "fnames = ['Coat{}.jpg'.format(i) for i in range(449,598)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_Coat_dir, fname)\n",
    "    shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['Cotten_long_pants{}.jpg'.format(i) for i in range(86)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_Cotten_long_pants_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "\n",
    "fnames = ['Cotten_long_pants{}.jpg'.format(i) for i in range(86,129)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_Cotten_long_pants_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "    \n",
    "fnames = ['Cotten_long_pants{}.jpg'.format(i) for i in range(129,172)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_Cotten_long_pants_dir, fname)\n",
    "    shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['Cutoffs{}.jpg'.format(i) for i in range(249)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_Cutoffs_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "\n",
    "fnames = ['Cutoffs{}.jpg'.format(i) for i in range(249,373)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_Cutoffs_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "    \n",
    "fnames = ['Cutoffs{}.jpg'.format(i) for i in range(373,497)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_Cutoffs_dir, fname)\n",
    "    shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['H_line{}.jpg'.format(i) for i in range(265)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_H_line_skirt_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "\n",
    "fnames = ['H_line{}.jpg'.format(i) for i in range(265,397)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_H_line_skirt_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "    \n",
    "fnames = ['H_line{}.jpg'.format(i) for i in range(397,529)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_H_line_skirt_dir, fname)\n",
    "    shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['Hoodie{}.jpg'.format(i) for i in range(1253)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_Hoodie_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "\n",
    "fnames = ['Hoodie{}.jpg'.format(i) for i in range(1253,1880)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_Hoodie_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "    \n",
    "fnames = ['Hoodie{}.jpg'.format(i) for i in range(1880,2506)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_Hoodie_dir, fname)\n",
    "    shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['Jacket{}.jpg'.format(i) for i in range(428)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_Jacket_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "\n",
    "fnames = ['Jacket{}.jpg'.format(i) for i in range(428,641)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_Jacket_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "    \n",
    "fnames = ['Jacket{}.jpg'.format(i) for i in range(641,855)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_Jacket_dir, fname)\n",
    "    shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['Jeans{}.jpg'.format(i) for i in range(600)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_Jeans_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "\n",
    "fnames = ['Jeans{}.jpg'.format(i) for i in range(600,300)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_Jeans_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "    \n",
    "fnames = ['Jeans{}.jpg'.format(i) for i in range(900,1200)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_Jeans_dir, fname)\n",
    "    shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['Long_sleeve_tee{}.jpg'.format(i) for i in range(160)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_Long_sleeve_tee_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "\n",
    "fnames = ['Long_sleeve_tee{}.jpg'.format(i) for i in range(160,239)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_Long_sleeve_tee_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "    \n",
    "fnames = ['Long_sleeve_tee{}.jpg'.format(i) for i in range(239,319)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_Long_sleeve_tee_dir, fname)\n",
    "    shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['Shirts{}.jpg'.format(i) for i in range(300)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_Shirts_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "\n",
    "fnames = ['Shirts{}.jpg'.format(i) for i in range(300,449)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_Shirts_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "    \n",
    "fnames = ['Shirts{}.jpg'.format(i) for i in range(449,599)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_Shirts_dir, fname)\n",
    "    shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['Short_sleeve_tee{}.jpg'.format(i) for i in range(636)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_Short_sleeve_tee_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "\n",
    "fnames = ['Short_sleeve_tee{}.jpg'.format(i) for i in range(636,954)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_Short_sleeve_tee_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "    \n",
    "fnames = ['Short_sleeve_tee{}.jpg'.format(i) for i in range(954,1272)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_Short_sleeve_tee_dir, fname)\n",
    "    shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['Sweater{}.jpg'.format(i) for i in range(336)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_Sweater_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "\n",
    "fnames = ['Sweater{}.jpg'.format(i) for i in range(336,503)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_Sweater_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "    \n",
    "fnames = ['Sweater{}.jpg'.format(i) for i in range(503,671)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_Sweater_dir, fname)\n",
    "    shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 15, 15, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 13)                6669      \n",
      "=================================================================\n",
      "Total params: 3,459,277\n",
      "Trainable params: 3,459,277\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(150,150,3)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512,activation='relu'))\n",
    "model.add(layers.Dense(13,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', #sparse_categorical_crossentropy\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5099 images belonging to 13 classes.\n",
      "Found 2245 images belonging to 13 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "train_dir,\n",
    "target_size=(150,150),\n",
    "batch_size=10,\n",
    "class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "validation_dir,\n",
    "target_size=(150,150),\n",
    "batch_size=10,\n",
    "class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 43s 429ms/step - loss: 2.2940 - acc: 0.2710 - val_loss: 2.2601 - val_acc: 0.2720\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 41s 408ms/step - loss: 1.9788 - acc: 0.3680 - val_loss: 2.0805 - val_acc: 0.2900\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 42s 421ms/step - loss: 1.7889 - acc: 0.4160 - val_loss: 1.8867 - val_acc: 0.3520\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 42s 415ms/step - loss: 1.7434 - acc: 0.4161 - val_loss: 1.8484 - val_acc: 0.3860\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 1.6728 - acc: 0.4330 - val_loss: 1.8266 - val_acc: 0.3840\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 40s 402ms/step - loss: 1.5832 - acc: 0.4440 - val_loss: 1.7665 - val_acc: 0.4120\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 40s 405ms/step - loss: 1.5360 - acc: 0.5056 - val_loss: 1.7591 - val_acc: 0.4240\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 1.4172 - acc: 0.5330 - val_loss: 1.8068 - val_acc: 0.4160\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 40s 402ms/step - loss: 1.3794 - acc: 0.5370 - val_loss: 1.8204 - val_acc: 0.4080\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 40s 405ms/step - loss: 1.4002 - acc: 0.5190 - val_loss: 1.7210 - val_acc: 0.4140\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 40s 402ms/step - loss: 1.2698 - acc: 0.5820 - val_loss: 1.6594 - val_acc: 0.4820\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 40s 404ms/step - loss: 1.2679 - acc: 0.5730 - val_loss: 1.6621 - val_acc: 0.4640\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 41s 408ms/step - loss: 1.2731 - acc: 0.5820 - val_loss: 1.6143 - val_acc: 0.4880\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 40s 401ms/step - loss: 1.2229 - acc: 0.5940 - val_loss: 1.6187 - val_acc: 0.4900\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 40s 403ms/step - loss: 1.2362 - acc: 0.5850 - val_loss: 1.5324 - val_acc: 0.5020\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 40s 402ms/step - loss: 1.1533 - acc: 0.6037 - val_loss: 1.6008 - val_acc: 0.4920\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 40s 403ms/step - loss: 1.1456 - acc: 0.6117 - val_loss: 1.7190 - val_acc: 0.4560\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 40s 403ms/step - loss: 1.0685 - acc: 0.6420 - val_loss: 1.6012 - val_acc: 0.5000\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 41s 406ms/step - loss: 1.0730 - acc: 0.6390 - val_loss: 1.5773 - val_acc: 0.4880\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 41s 405ms/step - loss: 1.0784 - acc: 0.6400 - val_loss: 1.6538 - val_acc: 0.5140\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('clothes_category_64.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label = 'Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label = 'Validation acc')\n",
    "# plt.tilte('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label = 'Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label = 'Validation loss')\n",
    "# plt.tilte('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.preprocessing import image\n",
    "\n",
    "# fnames = sorted([os.path.join(train_coat_dir, fname) for fname in os.listdir(train_c)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights = 'imagenet',\n",
    "                 include_top=False,\n",
    "                 input_shape=(150,150,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "base_dir = './data/clothes_category_small'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5099 images belonging to 13 classes.\n",
      "Found 2245 images belonging to 13 classes.\n",
      "Found 2547 images belonging to 13 classes.\n"
     ]
    }
   ],
   "source": [
    "def extract_features(directory,sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "    labels = np.zeros(shape=(sample_count,13))\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(150,150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "    return features, labels\n",
    "\n",
    "train_features, train_labels = extract_features(train_dir, 4000) #5096\n",
    "validation_features, validation_labels = extract_features(validation_dir, 2000) # 2548\n",
    "test_features, test_labels = extract_features(test_dir, 2000) #2547"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.reshape(train_features,(4000,4*4*512))\n",
    "validation_features = np.reshape(validation_features,(2000,4*4*512))\n",
    "test_features = np.reshape(test_features,(2000,4*4*512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras import models, layers, optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_dim = 4 * 4 * 512))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(13, activation='softmax'))\n",
    "model.compile(optimizer = optimizers.RMSprop(lr=2e-5),\n",
    "                         loss='categorical_crossentropy',\n",
    "                         metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
    "mc = ModelCheckpoint('best_model_pattern_0423.h5', monitor='val_loss', mode='min', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4000 samples, validate on 2000 samples\n",
      "Epoch 1/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.1979 - acc: 0.3193 - val_loss: 1.8981 - val_acc: 0.3995\n",
      "Epoch 2/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.7063 - acc: 0.4650 - val_loss: 1.6679 - val_acc: 0.4990\n",
      "Epoch 3/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.4522 - acc: 0.5458 - val_loss: 1.5143 - val_acc: 0.5350\n",
      "Epoch 4/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3103 - acc: 0.5842 - val_loss: 1.4352 - val_acc: 0.5495\n",
      "Epoch 5/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.1719 - acc: 0.6315 - val_loss: 1.3623 - val_acc: 0.5665\n",
      "Epoch 6/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.0745 - acc: 0.6638 - val_loss: 1.2967 - val_acc: 0.5835\n",
      "Epoch 7/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.0195 - acc: 0.6815 - val_loss: 1.2737 - val_acc: 0.5970\n",
      "Epoch 8/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.9484 - acc: 0.7035 - val_loss: 1.2570 - val_acc: 0.5955\n",
      "Epoch 9/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.9004 - acc: 0.7192 - val_loss: 1.2074 - val_acc: 0.6025\n",
      "Epoch 10/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.8576 - acc: 0.7235 - val_loss: 1.1775 - val_acc: 0.6160\n",
      "Epoch 11/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.8186 - acc: 0.7410 - val_loss: 1.1773 - val_acc: 0.6190\n",
      "Epoch 12/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.7825 - acc: 0.7513 - val_loss: 1.1492 - val_acc: 0.6290\n",
      "Epoch 13/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.7490 - acc: 0.7665 - val_loss: 1.1735 - val_acc: 0.6160\n",
      "Epoch 14/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.7202 - acc: 0.7733 - val_loss: 1.1263 - val_acc: 0.6375\n",
      "Epoch 15/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.6871 - acc: 0.7810 - val_loss: 1.1484 - val_acc: 0.6265\n",
      "Epoch 16/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.6553 - acc: 0.7993 - val_loss: 1.0921 - val_acc: 0.6365\n",
      "Epoch 17/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.6304 - acc: 0.7965 - val_loss: 1.1042 - val_acc: 0.6400\n",
      "Epoch 18/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.6113 - acc: 0.8145 - val_loss: 1.0958 - val_acc: 0.6475\n",
      "Epoch 19/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.5907 - acc: 0.8170 - val_loss: 1.0859 - val_acc: 0.6540\n",
      "Epoch 20/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.5734 - acc: 0.8255 - val_loss: 1.0764 - val_acc: 0.6525\n",
      "Epoch 21/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.5512 - acc: 0.8317 - val_loss: 1.0696 - val_acc: 0.6510\n",
      "Epoch 22/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.5168 - acc: 0.8420 - val_loss: 1.0888 - val_acc: 0.6540\n",
      "Epoch 23/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.5041 - acc: 0.8528 - val_loss: 1.0661 - val_acc: 0.6585\n",
      "Epoch 24/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.4851 - acc: 0.8555 - val_loss: 1.0719 - val_acc: 0.6530\n",
      "Epoch 25/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.4771 - acc: 0.8580 - val_loss: 1.0524 - val_acc: 0.6635\n",
      "Epoch 26/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.4591 - acc: 0.8573 - val_loss: 1.0595 - val_acc: 0.6565\n",
      "Epoch 27/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.4406 - acc: 0.8702 - val_loss: 1.0577 - val_acc: 0.6560\n",
      "Epoch 28/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.4256 - acc: 0.8745 - val_loss: 1.0683 - val_acc: 0.6590\n",
      "Epoch 29/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.4126 - acc: 0.8817 - val_loss: 1.0527 - val_acc: 0.6575\n",
      "Epoch 30/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.4032 - acc: 0.8832 - val_loss: 1.0565 - val_acc: 0.6720\n",
      "Epoch 31/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.3837 - acc: 0.8910 - val_loss: 1.0703 - val_acc: 0.6670\n",
      "Epoch 32/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.3735 - acc: 0.8995 - val_loss: 1.0711 - val_acc: 0.6625\n",
      "Epoch 33/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.3662 - acc: 0.8977 - val_loss: 1.0666 - val_acc: 0.6605\n",
      "Epoch 34/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.3590 - acc: 0.9032 - val_loss: 1.0686 - val_acc: 0.6645\n",
      "Epoch 35/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.3422 - acc: 0.9085 - val_loss: 1.0820 - val_acc: 0.6705\n",
      "Epoch 36/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.3341 - acc: 0.9105 - val_loss: 1.0747 - val_acc: 0.6685\n",
      "Epoch 37/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.3256 - acc: 0.9120 - val_loss: 1.0771 - val_acc: 0.6660\n",
      "Epoch 38/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.3183 - acc: 0.9142 - val_loss: 1.0652 - val_acc: 0.6730\n",
      "Epoch 39/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.2992 - acc: 0.9220 - val_loss: 1.0858 - val_acc: 0.6660\n",
      "Epoch 40/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.2911 - acc: 0.9240 - val_loss: 1.0789 - val_acc: 0.6630\n",
      "Epoch 41/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.2913 - acc: 0.9227 - val_loss: 1.0795 - val_acc: 0.6715\n",
      "Epoch 42/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.2725 - acc: 0.9277 - val_loss: 1.0848 - val_acc: 0.6720\n",
      "Epoch 43/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.2651 - acc: 0.9360 - val_loss: 1.0652 - val_acc: 0.6735\n",
      "Epoch 44/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.2664 - acc: 0.9320 - val_loss: 1.0733 - val_acc: 0.6735\n",
      "Epoch 45/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.2544 - acc: 0.9342 - val_loss: 1.0691 - val_acc: 0.6680\n",
      "Epoch 46/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.2398 - acc: 0.9412 - val_loss: 1.0793 - val_acc: 0.6735\n",
      "Epoch 47/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.2383 - acc: 0.9432 - val_loss: 1.0768 - val_acc: 0.6795\n",
      "Epoch 48/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.2275 - acc: 0.9455 - val_loss: 1.1055 - val_acc: 0.6700\n",
      "Epoch 49/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.2265 - acc: 0.9470 - val_loss: 1.0817 - val_acc: 0.6700\n",
      "Epoch 50/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.2189 - acc: 0.9497 - val_loss: 1.1041 - val_acc: 0.6755\n",
      "Epoch 51/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.2162 - acc: 0.9497 - val_loss: 1.0746 - val_acc: 0.6770\n",
      "Epoch 52/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.1974 - acc: 0.9557 - val_loss: 1.1013 - val_acc: 0.6805\n",
      "Epoch 53/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.2016 - acc: 0.9535 - val_loss: 1.0989 - val_acc: 0.6685\n",
      "Epoch 54/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.1925 - acc: 0.9560 - val_loss: 1.1220 - val_acc: 0.6760\n",
      "Epoch 55/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.1910 - acc: 0.9565 - val_loss: 1.1003 - val_acc: 0.6740\n",
      "Epoch 56/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.1781 - acc: 0.9585 - val_loss: 1.1033 - val_acc: 0.6705\n",
      "Epoch 57/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.1799 - acc: 0.9597 - val_loss: 1.1146 - val_acc: 0.6725\n",
      "Epoch 58/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.1682 - acc: 0.9607 - val_loss: 1.1067 - val_acc: 0.6745\n",
      "Epoch 59/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.1726 - acc: 0.9615 - val_loss: 1.1083 - val_acc: 0.6705\n",
      "Epoch 60/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.1622 - acc: 0.9635 - val_loss: 1.1228 - val_acc: 0.6695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.1576 - acc: 0.9660 - val_loss: 1.1465 - val_acc: 0.6745\n",
      "Epoch 62/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.1496 - acc: 0.9727 - val_loss: 1.1401 - val_acc: 0.6700\n",
      "Epoch 63/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.1508 - acc: 0.9672 - val_loss: 1.1409 - val_acc: 0.6680\n",
      "Epoch 64/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.1420 - acc: 0.9737 - val_loss: 1.1413 - val_acc: 0.6810\n",
      "Epoch 65/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.1465 - acc: 0.9697 - val_loss: 1.1556 - val_acc: 0.6700\n",
      "Epoch 66/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.1359 - acc: 0.9710 - val_loss: 1.1686 - val_acc: 0.6735\n",
      "Epoch 67/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.1311 - acc: 0.9755 - val_loss: 1.1597 - val_acc: 0.6720\n",
      "Epoch 68/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.1289 - acc: 0.9745 - val_loss: 1.1606 - val_acc: 0.6815\n",
      "Epoch 69/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.1252 - acc: 0.9725 - val_loss: 1.1668 - val_acc: 0.6745\n",
      "Epoch 70/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.1241 - acc: 0.9757 - val_loss: 1.1607 - val_acc: 0.6750\n",
      "Epoch 71/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.1238 - acc: 0.9755 - val_loss: 1.1708 - val_acc: 0.6715\n",
      "Epoch 72/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.1124 - acc: 0.9795 - val_loss: 1.1759 - val_acc: 0.6705\n",
      "Epoch 73/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.1139 - acc: 0.9765 - val_loss: 1.1526 - val_acc: 0.6690\n",
      "Epoch 74/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.1097 - acc: 0.9820 - val_loss: 1.1860 - val_acc: 0.6775\n",
      "Epoch 75/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.1071 - acc: 0.9785 - val_loss: 1.2027 - val_acc: 0.6685\n",
      "Epoch 76/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.1057 - acc: 0.9817 - val_loss: 1.1820 - val_acc: 0.6740\n",
      "Epoch 77/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.1021 - acc: 0.9815 - val_loss: 1.2126 - val_acc: 0.6735\n",
      "Epoch 78/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0983 - acc: 0.9830 - val_loss: 1.1879 - val_acc: 0.6725\n",
      "Epoch 79/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0949 - acc: 0.9835 - val_loss: 1.2217 - val_acc: 0.6650\n",
      "Epoch 80/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0916 - acc: 0.9870 - val_loss: 1.2071 - val_acc: 0.6680\n",
      "Epoch 81/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0882 - acc: 0.9852 - val_loss: 1.2190 - val_acc: 0.6700\n",
      "Epoch 82/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0882 - acc: 0.9837 - val_loss: 1.2140 - val_acc: 0.6685\n",
      "Epoch 83/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0816 - acc: 0.9877 - val_loss: 1.2086 - val_acc: 0.6755\n",
      "Epoch 84/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0818 - acc: 0.9855 - val_loss: 1.2417 - val_acc: 0.6720\n",
      "Epoch 85/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0823 - acc: 0.9842 - val_loss: 1.2103 - val_acc: 0.6715\n",
      "Epoch 86/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0758 - acc: 0.9872 - val_loss: 1.2448 - val_acc: 0.6730\n",
      "Epoch 87/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0729 - acc: 0.9882 - val_loss: 1.2113 - val_acc: 0.6725\n",
      "Epoch 88/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0736 - acc: 0.9897 - val_loss: 1.2405 - val_acc: 0.6765\n",
      "Epoch 89/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0726 - acc: 0.9860 - val_loss: 1.2265 - val_acc: 0.6795\n",
      "Epoch 90/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0713 - acc: 0.9862 - val_loss: 1.2338 - val_acc: 0.6695\n",
      "Epoch 91/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0633 - acc: 0.9912 - val_loss: 1.2484 - val_acc: 0.6725\n",
      "Epoch 92/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0650 - acc: 0.9915 - val_loss: 1.2646 - val_acc: 0.6730\n",
      "Epoch 93/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0641 - acc: 0.9892 - val_loss: 1.2639 - val_acc: 0.6660\n",
      "Epoch 94/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0633 - acc: 0.9920 - val_loss: 1.2903 - val_acc: 0.6745\n",
      "Epoch 95/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0596 - acc: 0.9912 - val_loss: 1.2839 - val_acc: 0.6665\n",
      "Epoch 96/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0561 - acc: 0.9927 - val_loss: 1.2698 - val_acc: 0.6700\n",
      "Epoch 97/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0603 - acc: 0.9912 - val_loss: 1.2669 - val_acc: 0.6725\n",
      "Epoch 98/500\n",
      "4000/4000 [==============================] - 6s 1ms/step - loss: 0.0553 - acc: 0.9927 - val_loss: 1.2738 - val_acc: 0.6705\n",
      "Epoch 99/500\n",
      "4000/4000 [==============================] - 6s 1ms/step - loss: 0.0530 - acc: 0.9932 - val_loss: 1.2844 - val_acc: 0.6730\n",
      "Epoch 100/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0511 - acc: 0.9940 - val_loss: 1.3062 - val_acc: 0.6715\n",
      "Epoch 101/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0518 - acc: 0.9910 - val_loss: 1.2854 - val_acc: 0.6625\n",
      "Epoch 102/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0513 - acc: 0.9940 - val_loss: 1.2792 - val_acc: 0.6695\n",
      "Epoch 103/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0470 - acc: 0.9957 - val_loss: 1.2893 - val_acc: 0.6705\n",
      "Epoch 104/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0478 - acc: 0.9935 - val_loss: 1.3176 - val_acc: 0.6670\n",
      "Epoch 105/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0482 - acc: 0.9925 - val_loss: 1.3224 - val_acc: 0.6765\n",
      "Epoch 106/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0428 - acc: 0.9955 - val_loss: 1.3062 - val_acc: 0.6720\n",
      "Epoch 107/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0437 - acc: 0.9945 - val_loss: 1.3000 - val_acc: 0.6785\n",
      "Epoch 108/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0433 - acc: 0.9930 - val_loss: 1.3189 - val_acc: 0.6710\n",
      "Epoch 109/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0428 - acc: 0.9945 - val_loss: 1.3337 - val_acc: 0.6730\n",
      "Epoch 110/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0432 - acc: 0.9937 - val_loss: 1.3204 - val_acc: 0.6670\n",
      "Epoch 111/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0363 - acc: 0.9957 - val_loss: 1.3428 - val_acc: 0.6720\n",
      "Epoch 112/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0380 - acc: 0.9957 - val_loss: 1.3331 - val_acc: 0.6720\n",
      "Epoch 113/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0371 - acc: 0.9955 - val_loss: 1.3417 - val_acc: 0.6670\n",
      "Epoch 114/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0388 - acc: 0.9940 - val_loss: 1.3284 - val_acc: 0.6695\n",
      "Epoch 115/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0356 - acc: 0.9950 - val_loss: 1.3526 - val_acc: 0.6730\n",
      "Epoch 116/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0356 - acc: 0.9960 - val_loss: 1.3693 - val_acc: 0.6680\n",
      "Epoch 117/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0353 - acc: 0.9957 - val_loss: 1.3504 - val_acc: 0.6705\n",
      "Epoch 118/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0327 - acc: 0.9960 - val_loss: 1.4058 - val_acc: 0.6715\n",
      "Epoch 119/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0329 - acc: 0.9957 - val_loss: 1.3579 - val_acc: 0.6685\n",
      "Epoch 120/500\n",
      "4000/4000 [==============================] - 6s 1ms/step - loss: 0.0300 - acc: 0.9975 - val_loss: 1.3663 - val_acc: 0.6720\n",
      "Epoch 121/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0289 - acc: 0.9977 - val_loss: 1.3628 - val_acc: 0.6715\n",
      "Epoch 122/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0300 - acc: 0.9965 - val_loss: 1.3687 - val_acc: 0.6665\n",
      "Epoch 123/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0289 - acc: 0.9972 - val_loss: 1.4217 - val_acc: 0.6650\n",
      "Epoch 124/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0254 - acc: 0.9982 - val_loss: 1.4006 - val_acc: 0.6650\n",
      "Epoch 125/500\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.0304 - acc: 0.9965 - val_loss: 1.4083 - val_acc: 0.6635\n",
      "Epoch 00125: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_features, train_labels,\n",
    "                   epochs=500,\n",
    "                   batch_size=20,\n",
    "                   validation_data=(validation_features, validation_labels),\n",
    "                   callbacks=[es,mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('category0423_best.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x228da1cb978>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x228da1a9e80>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label = 'Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label = 'Validation acc')\n",
    "# plt.tilte('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label = 'Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label = 'Validation loss')\n",
    "# plt.tilte('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = True\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name =='block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 13)                3341      \n",
      "=================================================================\n",
      "Total params: 2,100,749\n",
      "Trainable params: 2,100,749\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('category0423_88_66.h5') #   \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_7_input to have 2 dimensions, but got array with shape (10, 150, 150, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-70729a091275>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     validation_steps=50)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1274\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1275\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1276\u001b[1;33m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1278\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2222\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2223\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2224\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2226\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1875\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1876\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1877\u001b[1;33m             class_weight=class_weight)\n\u001b[0m\u001b[0;32m   1878\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1879\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m   1474\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1475\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1476\u001b[1;33m                                     exception_prefix='input')\n\u001b[0m\u001b[0;32m   1477\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[0;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    111\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    114\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected dense_7_input to have 2 dimensions, but got array with shape (10, 150, 150, 3)"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer = optimizers.RMSprop(lr=1e-5),\n",
    "             metrics = ['acc'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 100,\n",
    "    epochs=100,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_curve(points, factor-0.8):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "            else:\n",
    "                smoothed_points.append(point)\n",
    "    return smoothed_points\n",
    "\n",
    "\n",
    "plt.plot(epochs,\n",
    "        smooth_curve(acc), 'bo', label= 'Smoothed training acc')\n",
    "\n",
    "plt.plot(epochs,\n",
    "        smooth_curve(val_acc), 'b', label= 'Smoothed validation acc')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs,\n",
    "        smoothed_curve(loss), 'bo', label='Smoothed training loss')\n",
    "plt.plot(epochs,\n",
    "        smoothed_curve(val_loss), 'b', label='Smoothed validation loss')\n",
    "plt.tittle('Training and Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2547 images belonging to 13 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=20,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_11_input to have 2 dimensions, but got array with shape (20, 150, 150, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-7305404a5dfb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test acc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[1;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1316\u001b[0m                                              \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1317\u001b[0m                                              \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1318\u001b[1;33m                                              use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m   1319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[1;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2376\u001b[0m                                      \u001b[1;34m'or (x, y). Found: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2377\u001b[0m                                      str(generator_output))\n\u001b[1;32m-> 2378\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2380\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtest_on_batch\u001b[1;34m(self, x, y, sample_weight)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         x, y, sample_weights = self._standardize_user_data(\n\u001b[0;32m   1917\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m             sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m   1919\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1920\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m   1474\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1475\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1476\u001b[1;33m                                     exception_prefix='input')\n\u001b[0m\u001b[0;32m   1477\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[0;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    111\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    114\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected dense_11_input to have 2 dimensions, but got array with shape (20, 150, 150, 3)"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\n",
    "print('test acc:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[CPU_ENV]",
   "language": "python",
   "name": "cpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
